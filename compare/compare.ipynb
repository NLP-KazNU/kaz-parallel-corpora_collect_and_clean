{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import compare_utils as utils\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n",""]},{"cell_type":"markdown","metadata":{},"source":[" Download and prepare data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !wget http://data.statmt.org/wmt19/translation-task/kazakhtv.kk-en.tsv.gz\n","# !gunzip kazakhtv.kk-en.tsv.gz\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !wget http://data.statmt.org/wmt19/translation-task/crawl.2019-06.tsv.gz\n","# !gunzip crawl.2019-06.tsv.gz\n","\n","# https://drive.google.com/drive/folders/0B3f-xwS1hRdDM2VpZXRVblRRUmM?usp=sharing\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# !cat ../corpus/*.tsv > corpus.tsv\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cut crawl.2019-06.tsv -f 1 > crawl_kaz.txt\n","!cut crawl.2019-06.tsv -f 2 > crawl_eng.txt\n","!cut crawl.2019-06.tsv -f 3 > crawl_scores.txt\n","\n","!sacremoses -j 4 normalize < crawl_kaz.txt > crawl_kaz_norm.txt\n","!sed '/^$/d' crawl_kaz_norm.txt > crawl_kaz_norm2.txt\n","!sacremoses -j 4 tokenize -x < crawl_kaz_norm2.txt > crawl_kaz_tok.txt\n","!mv crawl_kaz_tok.txt crawl_kaz.txt\n","!rm crawl_kaz_norm.txt crawl_kaz_norm2.txt\n","\n","!sacremoses -j 4 normalize < crawl_eng.txt > crawl_eng_norm.txt\n","!sed '/^$/d' crawl_eng_norm.txt > crawl_eng_norm2.txt\n","!sacremoses -j 4 tokenize -x < crawl_eng_norm2.txt > crawl_eng_tok.txt\n","!mv crawl_eng_tok.txt crawl_eng.txt\n","!rm crawl_eng_norm.txt crawl_eng_norm2.txt\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cut kazakhtv.kk-en.tsv -f 1 > kazakhtv_kaz.txt\n","!cut kazakhtv.kk-en.tsv -f 2 > kazakhtv_eng.txt\n","!cut kazakhtv.kk-en.tsv -f 3 > kazakhtv_scores.txt\n","\n","!sacremoses -j 4 normalize < kazakhtv_kaz.txt > kazakhtv_kaz_norm.txt\n","!sed '/^$/d' kazakhtv_kaz_norm.txt > kazakhtv_kaz_norm2.txt\n","!sacremoses -j 4 tokenize -x < kazakhtv_kaz_norm2.txt > kazakhtv_kaz_tok.txt\n","!mv kazakhtv_kaz_tok.txt kazakhtv_kaz.txt\n","!rm kazakhtv_kaz_norm.txt kazakhtv_kaz_norm2.txt\n","\n","!sacremoses -j 4 normalize < kazakhtv_eng.txt > kazakhtv_eng_norm.txt\n","!sed '/^$/d' kazakhtv_eng_norm.txt > kazakhtv_eng_norm2.txt\n","!sacremoses -j 4 tokenize < kazakhtv_eng_norm2.txt > kazakhtv_eng_tok.txt\n","!mv kazakhtv_eng_tok.txt kazakhtv_eng.txt\n","!rm kazakhtv_eng_norm.txt kazakhtv_eng_norm2.txt\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cut KEKC.tsv -f 1 > old_corpus_kaz.txt\n","!cut KEKC.tsv -f 2 > old_corpus_eng.txt\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!cut corpus.tsv -f 1 > corpus_kaz.txt\n","!cut corpus.tsv -f 2 > corpus_eng.txt\n","!cut corpus.tsv -f 3 > corpus_scores.txt\n",""]},{"cell_type":"markdown","metadata":{},"source":[" Compare number of unique sentence pairs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def compare_unique_pairs():\n","    crawl_len = !cat crawl.2019-06.tsv | sort | uniq | wc -l\n","    kazakhtv_len = !cat kazakhtv.kk-en.tsv | sort | uniq | wc -l\n","    old_corpus_len = !cat KEKC.tsv | sort | uniq | wc -l\n","    corpus_len = !cat corpus.tsv | sort | uniq | wc -l\n","\n","    print(\"crawl size:\\t\", int(crawl_len[0]))\n","    print(\"kazakhtv size:\\t\", int(kazakhtv_len[0]))\n","    print(\"old_corpus size:\", int(old_corpus_len[0]))\n","    print(\"corpus size:\\t\", int(corpus_len[0]))\n","\n","    names = [\"crawl\", \"kazakhtv\", \"old_corpus\", \"corpus\"]\n","    sizes = [\n","        int(crawl_len[0]),\n","        int(kazakhtv_len[0]),\n","        int(old_corpus_len[0]),\n","        int(corpus_len[0])\n","    ]\n","\n","    plt.bar(x=names, height=sizes)\n","    plt.show()\n","\n","\n","compare_unique_pairs()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" Read data from files"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["crawl_kaz = utils.read_text_from_file_with_lower(file_name=\"crawl_kaz.txt\")\n","crawl_eng = utils.read_text_from_file_with_lower(file_name=\"crawl_eng.txt\")\n","crawl_scores = utils.read_floats_from_file(file_name=\"crawl_scores.txt\")\n","\n","kazakhtv_kaz = utils.read_text_from_file_with_lower(file_name=\"kazakhtv_kaz.txt\")\n","kazakhtv_eng = utils.read_text_from_file_with_lower(file_name=\"kazakhtv_eng.txt\")\n","kazakhtv_scores = utils.read_floats_from_file(file_name=\"kazakhtv_scores.txt\")\n","\n","old_corpus_kaz = utils.read_text_from_file_with_lower(file_name=\"old_corpus_kaz.txt\")\n","old_corpus_eng = utils.read_text_from_file_with_lower(file_name=\"old_corpus_eng.txt\")\n","\n","corpus_kaz = utils.read_text_from_file_with_lower(file_name=\"corpus_kaz.txt\")\n","corpus_eng = utils.read_text_from_file_with_lower(file_name=\"corpus_eng.txt\")\n","corpus_scores = utils.read_floats_from_file(file_name=\"corpus_scores.txt\")\n",""]},{"cell_type":"markdown","metadata":{},"source":[" Compare number of tokens in each language"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def compare_number_of_tokens():\n","    crawl_kaz_tok_num = utils.count_tokens(texts=crawl_kaz)\n","    crawl_eng_tok_num = utils.count_tokens(texts=crawl_eng)\n","\n","    kazakhtv_kaz_tok_num = utils.count_tokens(texts=kazakhtv_kaz)\n","    kazakhtv_eng_tok_num = utils.count_tokens(texts=kazakhtv_eng)\n","\n","    old_corpus_kaz_tok_num = utils.count_tokens(texts=old_corpus_kaz)\n","    old_corpus_eng_tok_num = utils.count_tokens(texts=old_corpus_eng)\n","\n","    corpus_kaz_tok_num = utils.count_tokens(texts=corpus_kaz)\n","    corpus_eng_tok_num = utils.count_tokens(texts=corpus_eng)\n","\n","    names = [\"crawl\", \"kazakhtv\", \"old_corpus\", \"corpus\"]\n","    sizes_kaz = [\n","        crawl_kaz_tok_num,\n","        kazakhtv_kaz_tok_num,\n","        old_corpus_kaz_tok_num,\n","        corpus_kaz_tok_num\n","    ]\n","    sizes_eng = [\n","        crawl_eng_tok_num,\n","        kazakhtv_eng_tok_num,\n","        old_corpus_eng_tok_num,\n","        corpus_eng_tok_num\n","    ]\n","\n","    for item in zip(names, sizes_kaz, sizes_eng):\n","        print(\n","            item[0], \": Kazakh tokens:\", item[1], \"English tokens:\", item[2]\n","        )\n","\n","    ind = np.arange(len(names))\n","    width = 0.35\n","    fig, ax = plt.subplots()\n","    rects1 = ax.bar(\n","        x=ind - width/2, height=sizes_kaz, width=width, label=\"kaz tokens\"\n","    )\n","    rects2 = ax.bar(\n","        x=ind + width/2, height=sizes_eng, width=width, label=\"eng tokens\"\n","    )\n","    ax.set_xticks(ind)\n","    ax.set_xticklabels(names)\n","    ax.legend()\n","    plt.grid(b=True, axis=\"y\")\n","    plt.show()\n","\n","\n","compare_number_of_tokens()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" Analyse and compare hunalign scores"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def compare_hunalign_scores():\n","    print(\"Hunalign scores analysis for crawl.2019-06 corpus:\")\n","    utils.analyze_scores(file_name=\"crawl_scores.txt\")\n","\n","    print(\"Hunalign scores analysis for kazakhtv corpus:\")\n","    utils.analyze_scores(file_name=\"kazakhtv_scores.txt\")\n","\n","    print(\"Hunalign scores analysis for new corpus:\")\n","    utils.analyze_scores(file_name=\"corpus_scores.txt\")\n","\n","\n","compare_hunalign_scores()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" Analyse and compare sentence lengths"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def compare_sentence_lengths():\n","    crawl_kaz_sen_lens = [len(line) for line in crawl_kaz]\n","    crawl_eng_sen_lens = [len(line) for line in crawl_eng]\n","\n","    kazakhtv_kaz_sen_lens = [len(line) for line in kazakhtv_kaz]\n","    kazakhtv_eng_sen_lens = [len(line) for line in kazakhtv_eng]\n","\n","    old_corpus_kaz_sen_lens = [len(line) for line in old_corpus_kaz]\n","    old_corpus_eng_sen_lens = [len(line) for line in old_corpus_eng]\n","\n","    corpus_kaz_sen_lens = [len(line) for line in corpus_kaz]\n","    corpus_eng_sen_lens = [len(line) for line in corpus_eng]\n","\n","    print(\"Sentense lengths analysis for crawl.2019-06 corpus (kazakh side):\")\n","    utils.analyze_sen_lens(lens=crawl_kaz_sen_lens)\n","\n","    print(\"Sentense lengths analysis for kazakhtv corpus (kazakh side):\")\n","    utils.analyze_sen_lens(lens=kazakhtv_kaz_sen_lens)\n","\n","    print(\"Sentense lengths analysis for old corpus (kazakh side):\")\n","    utils.analyze_sen_lens(lens=old_corpus_kaz_sen_lens)\n","\n","    print(\"Sentense lengths analysis for new corpus (kazakh side):\")\n","    utils.analyze_sen_lens(lens=corpus_kaz_sen_lens)\n","\n","    print(\"Sentense lengths analysis for crawl.2019-06 corpus (english side):\")\n","    utils.analyze_sen_lens(lens=crawl_eng_sen_lens)\n","\n","    print(\"Sentense lengths analysis for kazakhtv corpus (english side):\")\n","    utils.analyze_sen_lens(lens=kazakhtv_eng_sen_lens)\n","\n","    print(\"Sentense lengths analysis for old corpus (english side):\")\n","    utils.analyze_sen_lens(lens=old_corpus_eng_sen_lens)\n","\n","    print(\"Sentense lengths analysis for new corpus (english side):\")\n","    utils.analyze_sen_lens(lens=corpus_eng_sen_lens)\n","\n","\n","compare_sentence_lengths()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" Analyse and compare words"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def analyze_tokens_with_tf_idf():\n","    print(\"Kazakh side of corpora.\")\n","    print()\n","    tf_idf_vectorizer = TfidfVectorizer(max_features=20)\n","\n","    print(\"crawl_kaz:\")\n","    model = tf_idf_vectorizer.fit(raw_documents=crawl_kaz)\n","    print(\"20 most common tokens:\")\n","    print(model.get_feature_names())\n","    print()\n","\n","    print(\"kazakhtv_kaz:\")\n","    model = tf_idf_vectorizer.fit(raw_documents=kazakhtv_kaz)\n","    print(\"20 most common tokens:\")\n","    print(model.get_feature_names())\n","    print()\n","\n","    print(\"old_corpus_kaz:\")\n","    model = tf_idf_vectorizer.fit(raw_documents=old_corpus_kaz)\n","    print(\"20 most common tokens:\")\n","    print(model.get_feature_names())\n","    print()\n","\n","    print(\"corpus_kaz:\")\n","    model = tf_idf_vectorizer.fit(raw_documents=corpus_kaz)\n","    print(\"20 most common tokens:\")\n","    print(model.get_feature_names())\n","    print()\n","\n","    print(\"English side of corpora.\")\n","    print()\n","    tf_idf_vectorizer = TfidfVectorizer(max_features=20, stop_words=\"english\")\n","\n","    print(\"crawl_eng:\")\n","    model = tf_idf_vectorizer.fit(raw_documents=crawl_eng)\n","    print(\"20 most common tokens:\")\n","    print(model.get_feature_names())\n","    print()\n","\n","    print(\"kazakhtv_eng:\")\n","    model = tf_idf_vectorizer.fit(raw_documents=kazakhtv_eng)\n","    print(\"20 most common tokens:\")\n","    print(model.get_feature_names())\n","    print()\n","\n","    print(\"old_corpus_eng:\")\n","    model = tf_idf_vectorizer.fit(raw_documents=old_corpus_eng)\n","    print(\"20 most common tokens:\")\n","    print(model.get_feature_names())\n","    print()\n","\n","    print(\"corpus_eng:\")\n","    model = tf_idf_vectorizer.fit(raw_documents=corpus_eng)\n","    print(\"20 most common tokens:\")\n","    print(model.get_feature_names())\n","    print()\n","\n","\n","analyze_tokens_with_tf_idf()\n",""]},{"cell_type":"markdown","metadata":{},"source":[" Analyse and compare chars"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Kazakh side of corpora.\")\n","print()\n","print(\"crawl_kaz:\")\n","utils.analyze_chars(text=crawl_kaz, n_chars_to_print=None)\n","print()\n","print(\"kazakhtv_kaz:\")\n","utils.analyze_chars(text=kazakhtv_kaz, n_chars_to_print=None)\n","print()\n","print(\"old_corpus_kaz:\")\n","utils.analyze_chars(text=old_corpus_kaz, n_chars_to_print=None)\n","print()\n","print(\"corpus_kaz:\")\n","utils.analyze_chars(text=corpus_kaz, n_chars_to_print=None)\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}